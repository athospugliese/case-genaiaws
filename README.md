# ğŸ§  Case Desenvolvedor GenAI AWS

## ğŸš€ **Desafio**
O objetivo deste desafio Ã© criar uma soluÃ§Ã£o utilizando as bibliotecas **Langchain** e **Langgraph**, com a seguinte estrutura:

### ğŸ¯ **Requisitos**
1. **Agente Conversacional**: 
   - Interage com o usuÃ¡rio em qualquer tema, exceto **Engenharia Civil**.
   - A resposta final ao usuÃ¡rio deve ser proveniente deste agente.

2. **Agente de Busca**:
   - Realiza buscas com um limite de **10 retornos** por consulta.
   - Ã‰ acionado apenas quando necessÃ¡rio pelo Agente Conversacional.

3. **API PÃºblica**:
   - Criada com **FastAPI**, esta API:
     - Recebe perguntas do usuÃ¡rio.
     - Retorna respostas apenas do Agente Conversacional.
   - Deve rodar em um ambiente com **Kubernetes** e **Docker**.

4. **Modelos DisponÃ­veis**:
   - Suporte aos seguintes modelos:
     - ğŸŸ¢ **GPT-4o-mini**: Respostas rÃ¡pidas e precisas.
     - ğŸŸ¢ **GPT-4o**: Modelo avanÃ§ado para tarefas complexas.
     - ğŸ”µ **Llama-3.1-8B-Instant**: Modelo leve para respostas rÃ¡pidas.
     - ğŸ”µ **Llama-3.3-70B-Versatile**: VersÃ¡til para demandas complexas.
     - ğŸŸ¡ **Llama-Guard-3-8B**: Focado em moderaÃ§Ã£o de conteÃºdo.
     - ğŸŸ¡ **DeepSeek-R1-Distill-Llama-70B**: Para anÃ¡lises profundas e buscas.

---

## ğŸ“‚ **Estrutura de DiretÃ³rios**

### ğŸ“¦ DiretÃ³rio `/src`

#### ğŸ§© **Agentes (`/src/agents`)**
- **`agents.py`**: ImplementaÃ§Ã£o dos agentes conversacional e de busca.
- **`llama_guard.py`**: ModeraÃ§Ã£o de conteÃºdo com LlamaGuard.
- **`supervisor.py`**: Gerenciamento da comunicaÃ§Ã£o entre agentes.
- **`utils.py`**: UtilitÃ¡rios para operaÃ§Ã£o dos agentes.

#### ğŸ’» **Cliente (`/src/client`)**
- **`client.py`**: Gerencia conexÃµes entre a API e os agentes.

#### ğŸ”§ **Core (`/src/core`)**
- **`llm.py`**: Configura e integra os modelos disponÃ­veis.
- **`settings.py`**: ConfiguraÃ§Ãµes principais do sistema.

#### ğŸ—‚ **Schemas (`/src/schema`)**
- **`models.py`**: Define modelos e dados estruturados.
- **`task_data.py`**: Estrutura para gerenciamento de dados.

#### ğŸ”Œ **ServiÃ§os (`/src/service`)**
- **`service.py`**: LÃ³gica principal do serviÃ§o.
- **`run_agent.py`**: Executa os agentes.
- **`run_service.py`**: Inicializa o serviÃ§o.

---


### ğŸ”’ **ModeraÃ§Ã£o com LlamaGuard** âœ‹ **PrevenÃ§Ã£o de ConteÃºdo Inseguro**
O **LlamaGuard** assegura que o conteÃºdo gerado seja seguro, classificando respostas em categorias de risco.  
**Principais Categorias de ViolaÃ§Ã£o**:
- **S1**: Crimes violentos.
- **S2**: Crimes nÃ£o violentos.
- **S3**: Crimes sexuais.
- **S4**: ExploraÃ§Ã£o infantil.
- **S5**: DifamaÃ§Ã£o.
- **S6**: Aconselhamento especializado.
- **S7**: Privacidade.
- **S8**: Propriedade intelectual.
- **S9**: Armas indiscriminadas.
- **S10**: Discurso de Ã³dio.
- **S11**: Auto-mutilaÃ§Ã£o.
- **S12**: ConteÃºdo sexual.
- **S13**: EleiÃ§Ãµes.
- **S14**: Abuso de interpretadores de cÃ³digo.

### ğŸ“Š **SaÃ­da de ModeraÃ§Ã£o**
A classe `LlamaGuardOutput` fornece:
- **safety_assessment**: AvaliaÃ§Ã£o geral da seguranÃ§a do conteÃºdo.
- **unsafe_categories**: Lista de categorias inseguras detectadas.

## DemonstraÃ§Ã£o

![App Screenshot](https://i.imgur.com/QkMF6Ln.png)

![App Screenshot](https://i.imgur.com/xUdmSv5.png)

---

## ğŸ“ˆ Feedback e Tracing com LangSmith e ğŸ“Œ Funcionalidades
#### Tracing:
Monitora fluxos de execuÃ§Ã£o dos agentes.
Identifica gargalos e erros em tempo real.
#### Feedback:
Captura avaliaÃ§Ãµes do usuÃ¡rio sobre a qualidade das respostas.
Dados sÃ£o usados para melhorar continuamente os agentes.
#### ğŸ” VisualizaÃ§Ã£o de Logs
Logs detalhados sÃ£o gerados pelo LangSmith para anÃ¡lise e otimizaÃ§Ã£o do desempenho.
##



## âš™ï¸ **Como Executar**

#### **ğŸ“‹ PrÃ©-requisitos**
- Docker e Kubernetes instalados.
- Python 3.12+.
- Conta AWS configurada (opcional).

### **â–¶ï¸ Passos**
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/athospugliese/case-genaiaws
   cd case-genaiaws
   python3 -m venv venv
   source venv/bin/activate  # Linux/MacOS
   .\venv\Scripts\activate  # Windows

   pip install -r requirements.txt

## ğŸš€ **InstruÃ§Ãµes de Docker e Kubernetes**

#### **ğŸ³ Criando a Imagem Docker**

Para criar a imagem Docker do seu projeto, siga estas etapas:

**Criar a Imagem Docker**:
   
   No diretÃ³rio do projeto, crie a imagem Docker com o seguinte comando:

    docker build -t nome-da-imagem .
    docker run -p 8000:8000 nome-da-imagem


#### **ğŸš¢ Implantando no Kubernetes**

Para criar a imagem Docker do seu projeto, siga estas etapas:

**ConfiguraÃ§Ã£o do Kubernetes**:

Certifique-se de ter o kubectl instalado e configurado corretamente. VocÃª deve criar um arquivo chamado deployment.yaml no diretÃ³rio do projeto com o seguinte conteÃºdo:

    apiVersion: apps/v1
    kind: Deployment
    metadata:
    name: nome-do-app
    spec:
    replicas: 3
    selector:
        matchLabels:
        app: nome-do-app
    template:
        metadata:
        labels:
            app: nome-do-app
        spec:
        containers:
        - name: nome-do-app
            image: nome-da-imagem:latest  # Nome da imagem Docker que vocÃª criou
            ports:
            - containerPort: 8000


**Criar o Deployment no Kubernetes**:
   
   Aplique o arquivo de configuraÃ§Ã£o para criar o Deployment no seu cluster Kubernetes com o primeiro comando
   Verifique se os PODs estÃ£o rodando com o segundo comando

    kubectl apply -f deployment.yaml
    kubectl get pods

**Expor o acesso**:
   
   Se vocÃª deseja expor seu serviÃ§o fora do cluster Kubernetes, crie um serviÃ§o com o seguinte comando:

    kubectl expose deployment nome-do-app --type=LoadBalancer --port=80 --target-port=8000





## Arquitetura AWS

![App Screenshot](https://i.imgur.com/VDusCAn.png)

![App Screenshot](https://i.imgur.com/PFF5eUX.png)
